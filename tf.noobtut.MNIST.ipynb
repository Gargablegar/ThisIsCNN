{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST for begginers on tf\n",
    "## A softmax regesion approach to MNIST classification\n",
    "- Code here is taken from this link https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "\n",
    "- Blog on Soft max in the context of MNIST (Very detailed explinations in maths and code form)\n",
    "http://neuralnetworksanddeeplearning.com/chap3.html#softmax\n",
    "\n",
    "- Blof that explaines cross entropy loss in detail\n",
    "http://colah.github.io/posts/2015-09-Visual-Information/\n",
    "\n",
    " (Softmax is often performed as a final step in more complex models)\n",
    "\n",
    "**First we get the data**\n",
    "The MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation). This split is very important: it's essential in machine learning that we have separate data which we don't learn from so that we can make sure that what we've learned actually generalizes!\n",
    "\n",
    "As mentioned earlier, every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. We'll call the images \"x\" and the labels \"y\". Both the training set and test set contain images and their corresponding labels; for example the training images are mnist.train.images and the training labels are mnist.train.labels.\n",
    "\n",
    "**Each image is 28 pixels by 28 pixels.**\n",
    "\n",
    "We can flatten this array into a vector of **28x28 = 784 numbers**. It doesn't matter how we flatten the array, as long as we're consistent between images. From this perspective, the MNIST images are just a bunch of points in a 784-dimensional vector space, with a very rich structure (warning: computationally intensive visualizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1214f8f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120995090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/42353676/display-mnist-image-using-matplotlib\n",
    "# Printing out image \n",
    "# Tested with Python 3.5.2 with tensorflow and matplotlib installed.\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# # Get data\n",
    "# # dont forget to manage your .gitignore MNIST_data/\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n",
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest')\n",
    "    return plt\n",
    "\n",
    "# Get a batch of two random images and show in a pop-up window.\n",
    "batch_xs, batch_ys = mnist.test.next_batch(2)\n",
    "gen_image(batch_xs[0]).show()\n",
    "gen_image(batch_xs[1]).show()\n",
    "\n",
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "We want to be able to input any number of MNIST images, each flattened into a 784-dimensional vector. We represent this as a 2-D tensor of floating-point numbers, with a shape [None, 784]. (Here None means that a dimension can be of any length.)\n",
    "\n",
    "x isn't a specific value. It's a ***placeholder***, a value that we'll input when we ask TensorFlow to run a computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the weights and biases for our model. We could imagine treating these like additional inputs, but TensorFlow has an even better way to handle it: ***Variable***. A Variable is a modifiable tensor that lives in TensorFlow's graph of interacting operations. It can be used and even modified by the computation. For machine learning applications, one generally has the model parameters be ***Variables***.\n",
    "\n",
    "We create these Variables by giving tf.Variable the initial value of the Variable: in this case, we initialize both W and b as tensors full of zeros. Since we are going to learn W and b, it doesn't matter very much what they initially are.\n",
    "\n",
    "On Shape:\n",
    "\n",
    "Notice that W has a shape of [784, 10] because we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors of evidence for the difference classes. b has a shape of [10] so we can add it to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lol impliment model\n",
    "# Y = softmax(Wx + b)\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Using Cross entropy as the cost function \n",
    "> In some rough sense, the cross-entropy is measuring how inefficient our predictions are for describing the truth.\n",
    "https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners#Training\n",
    "\n",
    "Information on backpropogation\n",
    "http://colah.github.io/posts/2015-08-Backprop/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Placeholder\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "# implement the cross-entropy function\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your code, consider using tf.nn.softmax_cross_entropy_with_logits instead\n",
    "\n",
    "Now that we know what we want our model to do, it's very easy to have TensorFlow train it to do so. Because TensorFlow knows the entire graph of your computations, it can automatically use the **backpropagation** algorithm to efficiently determine how your variables affect the loss you ask it to minimize. Then it can apply your choice of optimization algorithm to modify the variables and reduce the loss.\n",
    "\n",
    "\n",
    "There other ways to optimise though: https://www.tensorflow.org/versions/r1.1/api_guides/python/train#Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model at a given step\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new TF session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run() #Dont forget to intitialise the variables for the session!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training loop\n",
    "Each step of the loop, we get a \"batch\" of one hundred random data points from our training set. We run train_step feeding in the batches data to replace the placeholders.\n",
    "\n",
    "Using small batches of random data is called stochastic training -- in this case, stochastic gradient descent. Ideally, we'd like to use all our data for every step of training because that would give us a better sense of what we should be doing, but that's expensive. So, instead, we use a different subset every time. Doing this is cheap and has much of the same benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop of 1000 iterations\n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
